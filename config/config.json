{
    "tokenizer": {
        "velocity_quantization": {
            "step": 5,
            "default": 60
        },
        "time_quantization": {
            "num_steps": 3000,
            "step": 10
        }
    },
    "audio": {
        "sample_rate": 16000,
        "n_fft_large": 2048,
        "n_fft_med": 2048,
        "n_fft_small": 800,
        "hop_len": 160,
        "chunk_len": 30,
        "n_mels_large": 384,
        "n_mels_med": 256,
        "n_mels_small": 128
    },
    "data": {
        "stride_factor": 15,
        "max_seq_len": 4096
    }
} 